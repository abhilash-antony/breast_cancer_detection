{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathology</th>\n",
       "      <th>left or right breast</th>\n",
       "      <th>image view</th>\n",
       "      <th>abnormality type</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.342386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.891800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.392091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.353764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BENIGN</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.145557...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pathology left or right breast image view abnormality type  \\\n",
       "0   MALIGNANT                 LEFT         CC             mass   \n",
       "2      BENIGN                 LEFT         CC             mass   \n",
       "5   MALIGNANT                RIGHT         CC             mass   \n",
       "8      BENIGN                RIGHT         CC             mass   \n",
       "10     BENIGN                 LEFT         CC             mass   \n",
       "\n",
       "                                           image_path  \n",
       "0   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.342386...  \n",
       "2   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.891800...  \n",
       "5   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.392091...  \n",
       "8   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.353764...  \n",
       "10  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.145557...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter DataFrame where 'image view' is 'CC'\n",
    "breast_cancer_df = pd.read_csv('CBIS-DDSM_combined.csv')\n",
    "df_cc = breast_cancer_df[breast_cancer_df['image view'] == 'CC']\n",
    "df_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the images using OpenCV and InceptionV3's required preprocessing\n",
    "def load_and_preprocess_image(image_path, img_size=(299, 299)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, img_size)  # Resize to target size (299x299 for InceptionV3)\n",
    "    img = img.astype('float32') / 255.0  # Normalize pixel values (0 to 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhil.LAPTOP-UDIMD39P\\AppData\\Local\\Temp\\ipykernel_8804\\3086398363.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cc['pathology'] = df_cc['pathology'].map({'MALIGNANT': 1, 'BENIGN': 0})\n"
     ]
    }
   ],
   "source": [
    "# Label encoding (MALIGNANT = 1, BENIGN = 0)\n",
    "df_cc['pathology'] = df_cc['pathology'].map({'MALIGNANT': 1, 'BENIGN': 0})\n",
    "\n",
    "# Prepare image paths and labels\n",
    "image_paths = df_cc['image_path'].values\n",
    "labels = df_cc['pathology'].values\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathology</th>\n",
       "      <th>left or right breast</th>\n",
       "      <th>image view</th>\n",
       "      <th>abnormality type</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.342386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.891800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.392091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.353764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>mass</td>\n",
       "      <td>CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.145557...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pathology left or right breast image view abnormality type  \\\n",
       "0           1                 LEFT         CC             mass   \n",
       "2           0                 LEFT         CC             mass   \n",
       "5           1                RIGHT         CC             mass   \n",
       "8           0                RIGHT         CC             mass   \n",
       "10          0                 LEFT         CC             mass   \n",
       "\n",
       "                                           image_path  \n",
       "0   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.342386...  \n",
       "2   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.891800...  \n",
       "5   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.392091...  \n",
       "8   CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.353764...  \n",
       "10  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.145557...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images using OpenCV\n",
    "X_train_processed = np.array([load_and_preprocess_image(img) for img in X_train])\n",
    "X_test_processed = np.array([load_and_preprocess_image(img) for img in X_test])\n",
    "\n",
    "# Convert labels to categorical (for binary classification)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "# Load the InceptionV3 model, pre-trained on ImageNet, without the top layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(2, activation='softmax')  # Binary classification (Benign, Malignant)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076, 299, 299, 3)\n",
      "(270, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_processed.shape)  # Should output (num_samples, 299, 299, 3)\n",
    "print(X_test_processed.shape)   # Should output (num_samples, 299, 299, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.5380 - loss: 0.7234 - val_accuracy: 0.5852 - val_loss: 0.6690\n",
      "Epoch 2/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6086 - loss: 0.6559 - val_accuracy: 0.5963 - val_loss: 0.6551\n",
      "Epoch 3/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6334 - loss: 0.6403 - val_accuracy: 0.5815 - val_loss: 0.6464\n",
      "Epoch 4/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6237 - loss: 0.6406 - val_accuracy: 0.5926 - val_loss: 0.6410\n",
      "Epoch 5/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6376 - loss: 0.6264 - val_accuracy: 0.6185 - val_loss: 0.6400\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_processed, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test_processed, y_test),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6265 - loss: 0.6310\n",
      "Test Accuracy: 0.6185\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_processed, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
